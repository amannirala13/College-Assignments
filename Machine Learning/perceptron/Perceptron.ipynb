{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cefcd5f-344f-4c78-9d86-a478be24171d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Perceptron\n",
    "*By Aman Kumar Nirala, 19030121010,\n",
    "amn1921010@sicsr.ac.in*\n",
    "\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "A perceptron is a single layer NN that is used as a linear classifier. A perceptron is a digital form of a neuron which is the building block of our nervous system.\n",
    "\n",
    "![Perceptron Image](img1.jpg)\n",
    "\n",
    "## How does it work?\n",
    "There are four major components of perceptrons that affects the output of the model,\n",
    "- Input\n",
    "- Weight\n",
    "- Bias\n",
    "- Activation function\n",
    "\n",
    "First an input is provided to the model which is then changes according to the weight and the bias for the respective input. This can be represented as:\n",
    "$$\n",
    "f(w,b) = x^Tw + b\n",
    "$$\n",
    "where w = weight tensor, x = input tensor, b = bias\n",
    "Once we get the output from this linear function we sum them up and pass it to the activation function which then gives the output. The mathematical relationship is shown below:\n",
    "$$\n",
    "\\hat{y} = c(x^Tw+b)\n",
    "$$\n",
    "where $$\\hat{y} = output$$ and $$c = \\left\\{\\begin{matrix}\n",
    "1 & \\textit{if}\\ x \\geq 0\\\\ \n",
    " 0& \\textit{else}\n",
    "\\end{matrix}\\right. $$\n",
    "\n",
    "While training, depending upon the output from the perceptron we calculate the error and adjust the weights and bias after every iteration. This can be represented as:\n",
    "$$\n",
    "w = w + \\Delta w\n",
    "$$\n",
    "$$\n",
    "\\Delta w = lr.x_i(y_i - \\hat{y_i})\n",
    "$$\n",
    "$$\n",
    "b = b + lr(y_i - \\hat{y_i})\n",
    "$$\n",
    "where lr = learning rate which ranges between 0 to 1\n",
    "\n",
    "Now lets implement it in python and test our implementation using a sample dataset for classification of breast cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1399a7-cf9e-403c-83f5-0c742a568567",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae51a499-6e64-48fd-ae54-b7663c178787",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@author: Aman Kumar Nirala (github.com/amannirala13)\n",
    "Created at: Fri Jun  4 18:33:55 2021\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b209a86-f273-4bbb-9091-f0bfa257d3fc",
   "metadata": {},
   "source": [
    "### Perceptron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1283958e-0bb5-4846-b857-119d371f637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron:\n",
    "    \n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        This is the primary constructor for the perceptron class. It takes in learning rate \n",
    "        and interations as arguments and initializes other variables \n",
    "    \n",
    "    ARGUMENTS:\n",
    "        # learning_rate -> Defines the learning rate i.e. lr of the model. Default = 0.01\n",
    "        # iterations -> Defines the number of time the model should train itself. \n",
    "        Default = 1000\n",
    "    '''\n",
    "    def __init__(self, learning_rate = 0.01, iterations = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        self.activation_func = self.step_func\n",
    "        \n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        This function takes in training data set and trains the perceptron.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        # X -> Independent variable set\n",
    "        # y -> Dependent variable set\n",
    "    '''\n",
    "    def fit(self, X, y):\n",
    "        n_sample, n_features = X.shape\n",
    "        self.weight = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        y = np.array([1 if i > 0 else 0 for i in y])\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            for index, x_i in enumerate(X):\n",
    "                y_predicted = self.predict(x_i)\n",
    "                delta = self.learning_rate * (y[index] - y_predicted)\n",
    "                self.weight += delta * x_i\n",
    "                self.bias = delta\n",
    "                \n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        This function returns the prediction set from the preceptron.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        # X -> Independent variable set\n",
    "    '''\n",
    "    def predict(self, X):\n",
    "        l_output = np.dot(X,self.weight) + self.bias\n",
    "        return self.activation_func(l_output)\n",
    "    \n",
    "    '''\n",
    "    DESCRIPTION:\n",
    "        The activation function which determins the final output of the perceptron depending\n",
    "        upon the input provided by the linear function.\n",
    "    \n",
    "    ARGUMENTS:\n",
    "        # X -> Input set from linear function\n",
    "    '''\n",
    "    def step_func(self, X):\n",
    "        return np.where(X >= 0, 1, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb489a-e72c-446a-8fc3-ad336e6aa429",
   "metadata": {},
   "source": [
    "### Cleaning and Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fbe88b-7ae5-41ac-9661-490c325d9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data = data.iloc[:,:-1]\n",
    "    data = data.iloc[:, 1:]\n",
    "    data[\"diagnosis\"] = data[\"diagnosis\"].map({'M':1, 'B':0})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d94d0-c21f-4d4e-b991-a42c2431d67b",
   "metadata": {},
   "source": [
    "### Dividing the data into Testing and Training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66606728-0375-4fa1-8750-1b5c1baac2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_outputs(data):\n",
    "    X = data.iloc[:, 2:]\n",
    "    y = data.loc[:, \"diagnosis\"]\n",
    "    X = pd.DataFrame(MinMaxScaler().fit_transform(X.values))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab39407-1644-4239-9c82-ceea65cb9ac3",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4943f7-55df-4424-991f-9542cd77d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data = pd.read_csv(\"data.csv\")\n",
    "    data = clean_data(data)\n",
    "    X, y = get_features_and_outputs(data)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 13)\n",
    "    \n",
    "    neuron = perceptron()\n",
    "    neuron.fit(np.array(X_train),np.array(y_train))\n",
    "    \n",
    "    y_pred = neuron.predict(np.array(X_test))\n",
    "    validity = np.where(y_pred == np.array(y_test), 1, 0)\n",
    "    accuracy = (np.sum(validity) / np.size(validity)) * 100\n",
    "    print('-----------------------------')\n",
    "    print(\"Accuracy = \",accuracy,\"%\")\n",
    "    print('-----------------------------')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df4648-0e07-46a1-bc8d-59f06b04292d",
   "metadata": {},
   "source": [
    "### Entry point of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dadded5-488e-4142-a8ca-972b4ed06f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "Accuracy =  95.6140350877193 %\n",
      "-----------------------------\n",
      "[[74  4]\n",
      " [ 1 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97        78\n",
      "           1       0.90      0.97      0.93        36\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.94      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651564ac-c181-485d-b343-12a495378338",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "As we can see the model with lr = 0.01 and after 1k iterations gave us an accuracy of about 96%. Thus we have successfully created a single level perceptron and used it for classifying a linear dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
